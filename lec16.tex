\documentclass[numbers=enddot,12pt,final,onecolumn,notitlepage]{scrartcl}%
\usepackage[headsepline,footsepline,manualmark]{scrlayer-scrpage}
\usepackage[all,cmtip]{xy}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{framed}
\usepackage{comment}
\usepackage{color}
\usepackage{hyperref}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{tikz}
\usepackage{needspace}
\usepackage{tabls}
\usepackage{wasysym}
\usepackage{easytable}
\usepackage{pythonhighlight}
%TCIDATA{OutputFilter=latex2.dll}
%TCIDATA{Version=5.50.0.2960}
%TCIDATA{LastRevised=Wednesday, October 27, 2021 11:50:16}
%TCIDATA{SuppressPackageManagement}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=Manual}
%TCIDATA{Language=American English}
%BeginMSIPreambleData
\providecommand{\U}[1]{\protect\rule{.1in}{.1in}}
%EndMSIPreambleData
\usetikzlibrary{arrows.meta}
\usetikzlibrary{chains}
\newcounter{exer}
\newcounter{exera}
\numberwithin{exer}{subsection}
\theoremstyle{definition}
\newtheorem{theo}{Theorem}[subsection]
\newenvironment{theorem}[1][]
{\begin{theo}[#1]\begin{leftbar}}
{\end{leftbar}\end{theo}}
\newtheorem{lem}[theo]{Lemma}
\newenvironment{lemma}[1][]
{\begin{lem}[#1]\begin{leftbar}}
{\end{leftbar}\end{lem}}
\newtheorem{prop}[theo]{Proposition}
\newenvironment{proposition}[1][]
{\begin{prop}[#1]\begin{leftbar}}
{\end{leftbar}\end{prop}}
\newtheorem{defi}[theo]{Definition}
\newenvironment{definition}[1][]
{\begin{defi}[#1]\begin{leftbar}}
{\end{leftbar}\end{defi}}
\newtheorem{remk}[theo]{Remark}
\newenvironment{remark}[1][]
{\begin{remk}[#1]\begin{leftbar}}
{\end{leftbar}\end{remk}}
\newtheorem{coro}[theo]{Corollary}
\newenvironment{corollary}[1][]
{\begin{coro}[#1]\begin{leftbar}}
{\end{leftbar}\end{coro}}
\newtheorem{conv}[theo]{Convention}
\newenvironment{convention}[1][]
{\begin{conv}[#1]\begin{leftbar}}
{\end{leftbar}\end{conv}}
\newtheorem{quest}[theo]{Question}
\newenvironment{question}[1][]
{\begin{quest}[#1]\begin{leftbar}}
{\end{leftbar}\end{quest}}
\newtheorem{warn}[theo]{Warning}
\newenvironment{warning}[1][]
{\begin{warn}[#1]\begin{leftbar}}
{\end{leftbar}\end{warn}}
\newtheorem{conj}[theo]{Conjecture}
\newenvironment{conjecture}[1][]
{\begin{conj}[#1]\begin{leftbar}}
{\end{leftbar}\end{conj}}
\newtheorem{exam}[theo]{Example}
\newenvironment{example}[1][]
{\begin{exam}[#1]\begin{leftbar}}
{\end{leftbar}\end{exam}}
\newtheorem{exmp}[exer]{Exercise}
\newenvironment{exercise}[1][]
{\begin{exmp}[#1]\begin{leftbar}}
{\end{leftbar}\end{exmp}}
\newenvironment{statement}{\begin{quote}}{\end{quote}}
\newenvironment{fineprint}{\medskip \begin{small}}{\end{small} \medskip}
\iffalse
\newenvironment{proof}[1][Proof]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\newenvironment{question}[1][Question]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\newenvironment{warning}[1][Warning]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\newenvironment{teachingnote}[1][Teaching note]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\fi
\let\sumnonlimits\sum
\let\prodnonlimits\prod
\let\cupnonlimits\bigcup
\let\capnonlimits\bigcap
\renewcommand{\sum}{\sumnonlimits\limits}
\renewcommand{\prod}{\prodnonlimits\limits}
\renewcommand{\bigcup}{\cupnonlimits\limits}
\renewcommand{\bigcap}{\capnonlimits\limits}
\setlength\tablinesep{3pt}
\setlength\arraylinesep{3pt}
\setlength\extrarulesep{3pt}
\voffset=0cm
\hoffset=-0.7cm
\setlength\textheight{22.5cm}
\setlength\textwidth{15.5cm}
\newcommand\arxiv[1]{\href{http://www.arxiv.org/abs/#1}{\texttt{arXiv:#1}}}
\newenvironment{verlong}{}{}
\newenvironment{vershort}{}{}
\newenvironment{noncompile}{}{}
\newenvironment{teachingnote}{}{}
\excludecomment{verlong}
\includecomment{vershort}
\excludecomment{noncompile}
\excludecomment{teachingnote}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\KK}{\mathbb{K}}
\newcommand{\id}{\operatorname{id}}
\newcommand{\lcm}{\operatorname{lcm}}
\newcommand{\rev}{\operatorname{rev}}
\newcommand{\powset}[2][]{\ifthenelse{\equal{#2}{}}{\mathcal{P}\left(#1\right)}{\mathcal{P}_{#1}\left(#2\right)}}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\tup}[1]{\left( #1 \right)}
\newcommand{\ive}[1]{\left[ #1 \right]}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\lf}[2]{#1^{\underline{#2}}}
\newcommand{\underbrack}[2]{\underbrace{#1}_{\substack{#2}}}
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}}
\newcommand{\are}{\ar@{-}}
\newcommand{\nnn}{\nonumber\\}
\newcommand{\sslash}{\mathbin{/\mkern-6mu/}}
\newcommand{\numboxed}[2]{\underbrace{\boxed{#1}}_{\text{box } #2}}
\newcommand{\ig}[2]{\includegraphics[scale=#1]{#2.png}}
\newcommand{\UNFINISHED}{\begin{center} \Huge{\textbf{Unfinished material begins here.}} \end{center} }
\iffalse
\NOEXPAND{\today}{\today}
\NOEXPAND{\sslash}{\sslash}
\NOEXPAND{\numboxed}[2]{\numboxed}
\NOEXPAND{\UNFINISHED}{\UNFINISHED}
\fi
\ihead{Math 504 notes}
\ohead{page \thepage}
\cfoot{\today}
\begin{document}

\title{Math 504: Advanced Linear Algebra}
\author{Hugo Woerdeman, with edits by Darij Grinberg\thanks{Drexel University, Korman
Center, 15 S 33rd Street, Philadelphia PA, 19104, USA}}
\date{\today\ (unfinished!)}
\maketitle
\tableofcontents

\section*{Math 504 Lecture 16}

\section{Hermitian matrices (cont'd)}

\textbf{Recall:} A \textbf{Hermitian matrix} is an $n\times n$-matrix
$A\in\mathbb{C}^{n\times n}$ such that $A^{\ast}=A$.

A Hermitian matrix $A$ is \textbf{positive semidefinite} if it satisfies%
\[
\left\langle Ax,x\right\rangle \geq0\ \ \ \ \ \ \ \ \ \ \text{for all }%
x\in\mathbb{C}^{n}.
\]


A Hermitian matrix $A$ is \textbf{positive definite} if it satisfies%
\[
\left\langle Ax,x\right\rangle >0\ \ \ \ \ \ \ \ \ \ \text{for all nonzero
}x\in\mathbb{C}^{n}.
\]


\subsection{The Cholesky decomposition}

\begin{theorem}
[Cholesky decomposition for positive definite matrices]Let $A\in
\mathbb{C}^{n\times n}$ be a positive definite Hermitian matrix. Then, $A$ has
a unique factorization of the form%
\[
A=LL^{\ast},
\]
where $L\in\mathbb{C}^{n\times n}$ is a lower-triangular matrix whose diagonal
entries are positive reals.
\end{theorem}

\begin{example}
For $n=1$, the theorem is trivial: In this case, $A=\left(
\begin{array}
[c]{c}%
a
\end{array}
\right)  $ for some $a\in\mathbb{R}$, and this $a$ is $>0$ because $A$ is
positive definite. Thus, setting $L=\left(
\begin{array}
[c]{c}%
\sqrt{a}%
\end{array}
\right)  $, then $A=LL^{\ast}$. Moreover, this is clearly the only choice.
\end{example}

\begin{example}
Let us manually check the theorem for $n=2$. Let $A=\left(
\begin{array}
[c]{cc}%
a & b\\
c & d
\end{array}
\right)  $ be a positive definite Hermitian matrix. We are looking for a
lower-triangular matrix $L=\left(
\begin{array}
[c]{cc}%
\lambda & 0\\
x & \delta
\end{array}
\right)  $ whose diagonal entries $\lambda$ and $\delta$ are positive reals
that satisfies $A=LL^{\ast}$.

So we need%
\begin{align*}
\left(
\begin{array}
[c]{cc}%
a & b\\
c & d
\end{array}
\right)    & =A=LL^{\ast}=\left(
\begin{array}
[c]{cc}%
\lambda & 0\\
x & \delta
\end{array}
\right)  \left(
\begin{array}
[c]{cc}%
\lambda & 0\\
x & \delta
\end{array}
\right)  ^{\ast}\\
& =\left(
\begin{array}
[c]{cc}%
\lambda & 0\\
x & \delta
\end{array}
\right)  \left(
\begin{array}
[c]{cc}%
\lambda & \overline{x}\\
0 & \delta
\end{array}
\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\lambda,\delta\text{ are
real}\right)  \\
& =\left(
\begin{array}
[c]{cc}%
\lambda^{2} & \lambda\overline{x}\\
\lambda x & x\overline{x}+\delta^{2}%
\end{array}
\right)  =\left(
\begin{array}
[c]{cc}%
\lambda^{2} & \lambda\overline{x}\\
\lambda x & \left\vert x\right\vert ^{2}+\delta^{2}%
\end{array}
\right)  .
\end{align*}
So we need to solve the system of equations%
\[
\left\{
\begin{array}
[c]{c}%
a=\lambda^{2};\\
b=\lambda\overline{x};\\
c=\lambda x;\\
d=\left\vert x\right\vert ^{2}+\delta^{2}.
\end{array}
\right.
\]


First, we solve the equation $a=\lambda^{2}$ by setting $\lambda=\sqrt{a}$.
Since $A$ is positive definite, we have $a=\left\langle Ae_{1},e_{1}%
\right\rangle >0$, so that $\sqrt{a}$ is well-defined, and we get a positive
real $\lambda$. Next, we solve the equation $c=\lambda x$ by setting
$x=\dfrac{c}{\lambda}$. Next, the equation $b=\lambda\overline{x}$ is
automatically satisfied, since the Hermitianness of $A$ entails $b=\overline
{c}=\overline{\lambda x}=\lambda\overline{x}$ (since $\lambda$ is real).
Finally, we solve the equation $d=\left\vert x\right\vert ^{2}+\delta^{2}$ by
setting $\delta=\sqrt{d-\left\vert x\right\vert ^{2}}$. Here, we need to
convince ourselves that $d-\left\vert x\right\vert ^{2}$ is a positive real,
i.e., that $d>\left\vert x\right\vert ^{2}$. Why is this the case?

I claim that this follows from applying $\left\langle Az,z\right\rangle \geq0$
to the vector $z=\left(
\begin{array}
[c]{c}%
b\\
-a
\end{array}
\right)  $. Indeed, setting $z=\left(
\begin{array}
[c]{c}%
b\\
-a
\end{array}
\right)  $, we obtain%
\[
Az=\left(
\begin{array}
[c]{cc}%
a & b\\
c & d
\end{array}
\right)  \left(
\begin{array}
[c]{c}%
b\\
-a
\end{array}
\right)  =\left(
\begin{array}
[c]{c}%
0\\
bc-ad
\end{array}
\right)  ,
\]
so that%
\[
\left\langle Az,z\right\rangle =\left\langle \left(
\begin{array}
[c]{c}%
0\\
bc-ad
\end{array}
\right)  ,\left(
\begin{array}
[c]{c}%
b\\
-a
\end{array}
\right)  \right\rangle =\left(  bc-ad\right)  \overline{-a}=a\left(
ad-bc\right)
\]
and thus $a\left(  ad-bc\right)  =\left\langle Az,z\right\rangle >0$ (by the
positive definiteness of $A$, since $z\neq0$). We can divide this inequality
by $a$ (since $a>0$), and obtain $ad-bc>0$. Now, recall that $x=\dfrac
{c}{\lambda}$ and $\lambda=\sqrt{a}$. Hence,%
\begin{align*}
d-\left\vert x\right\vert ^{2}  & =d-\left\vert \dfrac{c}{\lambda}\right\vert
^{2}=d-\dfrac{c\overline{c}}{\lambda^{2}}=d-\dfrac{cb}{a}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\overline{c}=b\text{ and }\lambda
^{2}=a\right)  \\
& =\dfrac{ad-bc}{a}>0\ \ \ \ \ \ \ \ \ \ \left(  \text{since }ad-bc>0\text{
and }a>0\right)  .
\end{align*}
This is what we need. So the theorem is proved for $n=2$.
\end{example}

To prove the theorem in general, we need a lemma that essentially generalizes
our above argument for $d-\left\vert x\right\vert ^{2}>0$:

\begin{lemma}
Let $Q\in\mathbb{C}^{n\times n}$ be a invertible matrix. Let $x\in
\mathbb{C}^{n}$ be some column vector. Let $d\in\mathbb{R}$. Let%
\[
A:=\left(
\begin{array}
[c]{cc}%
QQ^{\ast} & Qx\\
\left(  Qx\right)  ^{\ast} & d
\end{array}
\right)  \in\mathbb{C}^{\left(  n+1\right)  \times\left(  n+1\right)  }.
\]
Assume that $A$ is positive definite. Then, $\left\vert \left\vert
x\right\vert \right\vert ^{2}<d$.
\end{lemma}

\begin{proof}
Set $Q^{-\ast}:=\left(  Q^{-1}\right)  ^{\ast}=\left(  Q^{\ast}\right)  ^{-1}%
$. (This is well-defined, since $Q$ is invertible.) Set $u=\left(
\begin{array}
[c]{c}%
Q^{-\ast}x\\
-1
\end{array}
\right)  \in\mathbb{C}^{n+1}$. (This is in block-matrix notation. Explicitly,
this is the column vector obtained by appending the extra entry $-1$ at the
bottom of $Q^{-\ast}x$.)

Then,%
\begin{align*}
Au  & =\left(
\begin{array}
[c]{cc}%
QQ^{\ast} & Qx\\
\left(  Qx\right)  ^{\ast} & d
\end{array}
\right)  \left(
\begin{array}
[c]{c}%
Q^{-\ast}x\\
-1
\end{array}
\right)  =\left(
\begin{array}
[c]{c}%
QQ^{\ast}Q^{-\ast}x+Qx\left(  -1\right)  \\
\left(  Qx\right)  ^{\ast}Q^{-\ast}x+d\left(  -1\right)
\end{array}
\right)  \\
& =\left(
\begin{array}
[c]{c}%
0\\
x^{\ast}Q^{\ast}Q^{-\ast}x-d
\end{array}
\right)  =\left(
\begin{array}
[c]{c}%
0\\
x^{\ast}x-d
\end{array}
\right)  =\left(
\begin{array}
[c]{c}%
0\\
\left\vert \left\vert x\right\vert \right\vert ^{2}-d
\end{array}
\right)
\end{align*}
(since $x^{\ast}x=\left\langle x,x\right\rangle =\left\vert \left\vert
x\right\vert \right\vert ^{2}$). Hence,%
\[
\left\langle Au,u\right\rangle =\left\langle \left(
\begin{array}
[c]{c}%
0\\
\left\vert \left\vert x\right\vert \right\vert ^{2}-d
\end{array}
\right)  ,\left(
\begin{array}
[c]{c}%
Q^{-\ast}x\\
-1
\end{array}
\right)  \right\rangle =\left(  \left\vert \left\vert x\right\vert \right\vert
^{2}-d\right)  \left(  \overline{-1}\right)  =d-\left\vert \left\vert
x\right\vert \right\vert ^{2}.
\]
However, the vector $u$ is nonzero (since its last entry is $-1$), and the
matrix $A$ is positive definite (by assumption). Thus, $\left\langle
Au,u\right\rangle >0$. Since $\left\langle Au,u\right\rangle =d-\left\vert
\left\vert x\right\vert \right\vert ^{2}$, we thus obtain $d-\left\vert
\left\vert x\right\vert \right\vert ^{2}>0$. In other words, $d>\left\vert
\left\vert x\right\vert \right\vert ^{2}$. This proves the lemma.
\end{proof}

Now, let us prove the Cholesky factorization theorem:

\begin{proof}
[Proof of the Theorem.] We proceed by induction on $n$.

The \textit{base cases} $n=0$ and $n=1$ are essentially obvious ($n=1$ was
done in an example).

\textit{Induction step:} Assume that the theorem holds for some $n$. We must
prove that it holds for $n+1$ as well.

Let $A\in\mathbb{C}^{\left(  n+1\right)  \times\left(  n+1\right)  }$ be a
positive definite Hermitian matrix. Write $A$ in the form%
\[
A=\left(
\begin{array}
[c]{cc}%
B & b\\
b^{\ast} & d
\end{array}
\right)  ,
\]
where $B\in\mathbb{C}^{n\times n}$ and $b\in\mathbb{C}^{n}$. Note that the
$b^{\ast}$ on the bottom of the right hand side is because $A$ is Hermitian,
so all entries in the last row of $A$ are the complex conjugates of the
corresponding entries in the last column of $A$. Also, $d=d^{\ast}$ for the
same reason, so $d\in\mathbb{R}$. Moreover, $B$ is Hermitian (since $A$ is Hermitian).

Next, we claim that $B$ is positive definite. Indeed, for any nonzero vector
$x\in\mathbb{C}^{n}$, we have $\left\langle Bx,x\right\rangle =\left\langle
Ax^{\prime},x^{\prime}\right\rangle $, where $x^{\prime}=\left(
\begin{array}
[c]{c}%
x\\
0
\end{array}
\right)  $. Thus, positive definiteness of $B$ follows from positive
definiteness of $A$. (More generally, any principal submatrix of a positive
definite matrix is positive definite.)

Therefore, by the induction hypothesis, we can apply the theorem to $B$
instead of $A$. We conclude that $B$ can be uniquely written as a product
$B=QQ^{\ast}$, where $Q\in\mathbb{C}^{n\times n}$ is a lower-triangular matrix
whose diagonal entries are positive reals.

Now, we want to find a vector $x\in\mathbb{C}^{n}$ and a positive real
$\delta$ such that if we set%
\[
L:=\left(
\begin{array}
[c]{cc}%
Q & 0\\
x^{\ast} & \delta
\end{array}
\right)  ,
\]
then $A=LL^{\ast}$. If we can find such $x$ and $\delta$, then at least the
existence part of the theorem will be settled.

So let us set $L:=\left(
\begin{array}
[c]{cc}%
Q & 0\\
x^{\ast} & \delta
\end{array}
\right)  $, and see what conditions $A=LL^{\ast}$ places on $x$ and $\delta$.
We want%
\begin{align*}
\left(
\begin{array}
[c]{cc}%
B & b\\
b^{\ast} & d
\end{array}
\right)    & =A=LL^{\ast}=\left(
\begin{array}
[c]{cc}%
Q & 0\\
x^{\ast} & \delta
\end{array}
\right)  \left(
\begin{array}
[c]{cc}%
Q^{\ast} & \left(  x^{\ast}\right)  ^{\ast}\\
0 & \overline{\delta}%
\end{array}
\right)  \\
& =\left(
\begin{array}
[c]{cc}%
Q & 0\\
x^{\ast} & \delta
\end{array}
\right)  \left(
\begin{array}
[c]{cc}%
Q^{\ast} & x\\
0 & \delta
\end{array}
\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\delta\in\mathbb{R}%
\Longrightarrow\overline{\delta}=\delta\right)  \\
& =\left(
\begin{array}
[c]{cc}%
QQ^{\ast} & Qx\\
x^{\ast}Q^{\ast} & x^{\ast}x+\delta^{2}%
\end{array}
\right)  .
\end{align*}
In other words, we want%
\[
\left\{
\begin{array}
[c]{c}%
B=QQ^{\ast};\\
b=Qx;\\
b^{\ast}=x^{\ast}Q^{\ast};\\
d=x^{\ast}x+\delta^{2}.
\end{array}
\right.
\]
The first of these four equations is already satisfied (we know that
$B=QQ^{\ast}$). The second equation will be satisfied if we set $x=Q^{-1}b$.
We can indeed set $x=Q^{-1}b$, since the matrix $Q$ is invertible (since $Q$
is a lower-triangular matrix with positive reals on its diagonal). The third
equation follows automatically from the second ($b=Qx$ $\Longrightarrow$
$b^{\ast}=\left(  Qx\right)  ^{\ast}=x^{\ast}Q^{\ast}$). Finally, the fourth
equation rewrites as $d=\left\vert \left\vert x\right\vert \right\vert
^{2}+\delta^{2}$. We can satisfy it by setting $\delta=\sqrt{d-\left\vert
\left\vert x\right\vert \right\vert ^{2}}$, as long as we can show that
$d-\left\vert \left\vert x\right\vert \right\vert ^{2}>0$. Fortunately, we can
indeed show this, because our Lemma yields that $\left\vert \left\vert
x\right\vert \right\vert ^{2}<d$. Thus, we have found $x$ and $\delta$, and
constructed a lower-triangular matrix $L$ whose diagonal entries are positive
reals and which satisfies $A=LL^{\ast}$.

It remains to show that this $L$ is unique. Indeed, we can basically read our
argument above backwards. \textbf{If} $L\in\mathbb{C}^{\left(  n+1\right)
\times\left(  n+1\right)  }$ is a lower-triangular matrix whose diagonal
entries are positive reals and which satisfies $A=LL^{\ast}$, then we can
write $A$ in the form $A=\left(
\begin{array}
[c]{cc}%
Q & 0\\
x^{\ast} & \delta
\end{array}
\right)  $ for some $Q\in\mathbb{C}^{n\times n}$ and $x\in\mathbb{C}^{n}$ and
some positive real $\delta$, where $Q$ is lower-triangular with diagonal
entries being real. The equation $A=LL^{\ast}$ rewrites as%
\[
\left(
\begin{array}
[c]{cc}%
B & b\\
b^{\ast} & d
\end{array}
\right)  =\left(
\begin{array}
[c]{cc}%
QQ^{\ast} & Qx\\
x^{\ast}Q^{\ast} & x^{\ast}x+\delta^{2}%
\end{array}
\right)  .
\]
Thus, $B=QQ^{\ast}$. By the induction hypothesis, the $Q$ is unique, so this
$Q$ is exactly the $Q$ that was constructed above. Moreover, $b=Qx$, so that
$x=Q^{-1}b$, so again our new $x$ is our old $x$. Finally, $d=x^{\ast}%
x+\delta^{2}$ entails $\delta=\sqrt{d-\left\vert \left\vert x\right\vert
\right\vert ^{2}}$, because $\delta$ has to be positive. So our $\delta$ is
our old $\delta$. Thus, our $L$ is the $L$ that we constructed above. This
proves the uniqueness of the $L$. The theorem is proved.
\end{proof}

\begin{exercise}
Let $A\in\mathbb{C}^{n\times n}$ be a positive definite Hermitian matrix.
Then, $\det A$ is a positive real.
\end{exercise}

\begin{exercise}
Let $A$ and $B$ be two positive definite Hermitian matrices in $\mathbb{C}%
^{n\times n}$. Then, $\operatorname*{Tr}\left(  AB\right)  \geq0$.
\end{exercise}

There is a version of Cholesky decomposition for positive semidefinite
matrices, but this will be left to the exercises.

\subsection{Rayleigh quotients}

\begin{definition}
Let $A\in\mathbb{C}^{n\times n}$ be a Hermitian matrix, and $x\in
\mathbb{C}^{n}$ be a nonzero vector. Then, the \textbf{Rayleigh quotient} for
$A$ and $x$ is defined to be the real number%
\[
R\left(  A,x\right)  :=\dfrac{\left\langle Ax,x\right\rangle }{\left\langle
x,x\right\rangle }=\dfrac{x^{\ast}Ax}{x^{\ast}x}=\dfrac{x^{\ast}Ax}{\left\vert
\left\vert x\right\vert \right\vert ^{2}}=y^{\ast}Ay,
\]
where $y=\dfrac{x}{\left\vert \left\vert x\right\vert \right\vert }$.
\end{definition}

Let us explore what Rayleigh quotients can tell us about the eigenvalues of a
Hermitian matrix.

Let $A\in\mathbb{C}^{n\times n}$ be a Hermitian matrix with $n>0$. By the
spectral theorem, we have $A=UDU^{\ast}$ for some unitary $U$ and some real
diagonal matrix $D$. Consider these $U$ and $D$. We have
$D=\operatorname*{diag}\left(  \lambda_{1},\lambda_{2},\ldots,\lambda
_{n}\right)  $, where $\lambda_{1},\lambda_{2},\ldots,\lambda_{n}$ are the
eigenvalues of $A$. We WLOG that
\[
\lambda_{1}\leq\lambda_{2}\leq\cdots\leq\lambda_{n}%
\]
(indeed, we can always achieve this by permuting rows/columns of $D$ and
integrating the permutation matrices into $U$). We set%
\[
\lambda_{\min}\left(  A\right)  :=\lambda_{1}\ \ \ \ \ \ \ \ \ \ \text{and}%
\ \ \ \ \ \ \ \ \ \ \lambda_{\max}\left(  A\right)  :=\lambda_{n}.
\]
We will also write $\lambda_{\min}$ and $\lambda_{\max}$ without the
\textquotedblleft$\left(  A\right)  $\textquotedblright\ part.

Let us now pick some vector $x\in\mathbb{C}^{n}$ of length $1$ (that is,
$\left\vert \left\vert x\right\vert \right\vert =1$). Set $z=U^{\ast}x$. Then,
writing $z$ as $\left(
\begin{array}
[c]{c}%
z_{1}\\
z_{2}\\
\vdots\\
z_{n}%
\end{array}
\right)  $, we have%
\[
x^{\ast}Ax=\underbrace{x^{\ast}U}_{=\left(  U^{\ast}x\right)  ^{\ast}=z^{\ast
}}D\underbrace{U^{\ast}x}_{=z}=z^{\ast}Dz=\sum_{k=1}^{n}\lambda_{k}%
\overline{z_{k}}z_{k}=\sum_{k=1}^{n}\lambda_{k}\left\vert z_{k}\right\vert
^{2}.
\]
We note that $\left\vert \left\vert z\right\vert \right\vert =1$ (indeed,
since $U$ is unitary, the matrix $U^{\ast}$ is also unitary, so $\left\vert
\left\vert U^{\ast}x\right\vert \right\vert =\left\vert \left\vert
x\right\vert \right\vert =1$, which means $\left\vert \left\vert z\right\vert
\right\vert =1$). In other words, $\sum\limits_{k=1}^{n}\left\vert
z_{k}\right\vert ^{2}=1$ (since $\left\vert \left\vert z\right\vert
\right\vert =\sqrt{\sum\limits_{k=1}^{n}\left\vert z_{k}\right\vert ^{2}}$).
Now,%
\[
x^{\ast}Ax=\sum_{k=1}^{n}\underbrace{\lambda_{k}}_{\leq\lambda_{n}}\left\vert
z_{k}\right\vert ^{2}\leq\sum_{k=1}^{n}\lambda_{n}\left\vert z_{k}\right\vert
^{2}=\lambda_{n}\underbrace{\sum_{k=1}^{n}\left\vert z_{k}\right\vert ^{2}%
}_{=1}=\lambda_{n}.
\]


So we have shown that each vector $x\in\mathbb{C}^{n}$ of length $1$ satisfies
$x^{\ast}Ax\leq\lambda_{n}$. This inequality becomes an equality at least for
one vector $x$: namely, for the vector $x=Ue_{n}$ (because for this vector, we
have $z=\underbrace{U^{\ast}U}_{=I_{n}}e_{n}=e_{n}$, so that $z_{k}=0$ for all
$k<n$, and therefore the inequality $\sum_{k=1}^{n}\lambda_{k}\left\vert
z_{k}\right\vert ^{2}\leq\sum_{k=1}^{n}\lambda_{n}\left\vert z_{k}\right\vert
^{2}$ becomes an equality). Thus,%
\begin{align*}
\lambda_{n}  & =\max\left\{  x^{\ast}Ax\ \mid\ x\in\mathbb{C}^{n}\text{ is a
vector of length }1\right\}  \\
& =\max\left\{  \dfrac{x^{\ast}Ax}{x^{\ast}x}\ \mid\ x\in\mathbb{C}^{n}\text{
is nonzero}\right\}  \\
& =\max\left\{  R\left(  A,x\right)  \ \mid\ x\in\mathbb{C}^{n}\text{ is
nonzero}\right\}  .
\end{align*}
Since $\lambda_{n}=\lambda_{\max}\left(  A\right)  $, we thus have proved the
following fact:

\begin{proposition}
Let $A\in\mathbb{C}^{n\times n}$ be a Hermitian matrix with $n>0$. Then, the
largest eigenvalue of $A$ is%
\begin{align*}
\lambda_{\max}\left(  A\right)    & =\max\left\{  x^{\ast}Ax\ \mid
\ x\in\mathbb{C}^{n}\text{ is a vector of length }1\right\}  \\
& =\max\left\{  R\left(  A,x\right)  \ \mid\ x\in\mathbb{C}^{n}\text{ is
nonzero}\right\}  .
\end{align*}

\end{proposition}

Similarly:

\begin{proposition}
Let $A\in\mathbb{C}^{n\times n}$ be a Hermitian matrix with $n>0$. Then, the
smallest eigenvalue of $A$ is%
\begin{align*}
\lambda_{\max}\left(  A\right)    & =\min\left\{  x^{\ast}Ax\ \mid
\ x\in\mathbb{C}^{n}\text{ is a vector of length }1\right\}  \\
& =\min\left\{  R\left(  A,x\right)  \ \mid\ x\in\mathbb{C}^{n}\text{ is
nonzero}\right\}  .
\end{align*}

\end{proposition}

What about the other eigenvalues? Can we characterize $\lambda_{2}$ (for
example) in terms of Rayleigh quotients?

\begin{theorem}
[Courant--Fisher theorem]Let $A\in\mathbb{C}^{n\times n}$ be a Hermitian
matrix. Let $\lambda_{1},\lambda_{2},\ldots,\lambda_{n}$ be the eigenvalues of
$A$, with $\lambda_{1}\leq\lambda_{2}\leq\cdots\leq\lambda_{n}$. Then, for
each $k\in\left[  n\right]  $, we have%
\begin{align*}
\lambda_{k}  & =\min\left\{  \max\left\{  R\left(  A,x\right)  \ \mid\ x\in
S\text{ nonzero}\right\}  \ \mid\ S\subseteq\mathbb{C}^{n}\text{ is a
}k\text{-dimensional subspace}\right\}  \\
& =\min\limits_{\substack{S\subseteq\mathbb{C}^{n}\text{ is a subspace;}\\\dim
S=k}}\ \ \max\limits_{\substack{x\in S;\\x\neq0}}\ \ R\left(  A,x\right)
\end{align*}
and%
\begin{align*}
\lambda_{k}  & =\max\left\{  \min\left\{  R\left(  A,x\right)  \ \mid\ x\in
S\text{ nonzero}\right\}  \ \mid\ S\subseteq\mathbb{C}^{n}\text{ is a }\left(
n-k+1\right)  \text{-dimensional subspace}\right\}  \\
& =\max\limits_{\substack{S\subseteq\mathbb{C}^{n}\text{ is a subspace;}\\\dim
S=n-k+1}}\ \ \min\limits_{\substack{x\in S;\\x\neq0}}\ \ R\left(  A,x\right)
.
\end{align*}

\end{theorem}

We will prove this next time.


\end{document}